import streamlit as st
from youtube_transcript_api import YouTubeTranscriptApi
from youtube_transcript_api.formatters import TextFormatter
import google.generativeai as genai
import yt_dlp
import os
import re
import time
import requests
from PIL import Image
import nest_asyncio
import gc
import random
from io import BytesIO
from docx import Document
from docx.shared import Pt, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH

nest_asyncio.apply()

# --- 1. é é¢è¨­å®š ---
st.set_page_config(
    page_title="TrendScope Master | è…³æœ¬ç”Ÿæˆç‰ˆ",
    page_icon="ğŸ¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- 2. æ·±è‰²é«˜å°æ¯” UI ---
st.markdown("""
<style>
    .stApp { background-color: #0F172A !important; color: #E2E8F0 !important; }
    h1, h2, h3, h4, .stMarkdown { color: #F8FAFC !important; }
    
    /* æŒ‰éˆ•ï¼šæ·±æµ·è—æ¼¸å±¤ */
    .stButton > button {
        background: linear-gradient(135deg, #0f4c75 0%, #3282b8 100%) !important;
        color: white !important; font-weight: 800; padding: 0.8rem; border-radius: 8px;
        border: 1px solid #bbe1fa !important; letter-spacing: 1px;
    }
    .stButton > button:hover { transform: scale(1.02); box-shadow: 0 0 15px rgba(50, 130, 184, 0.6); }

    /* è¼¸å…¥æ¡† */
    .stTextArea textarea, .stTextInput input {
        background-color: #1E293B !important; color: white !important; border: 1px solid #475569 !important;
    }
    
    /* æ•¸æ“šå„€è¡¨æ¿ */
    .metric-card {
        background-color: #1e293b; border-left: 5px solid #3282b8;
        padding: 15px; border-radius: 8px; text-align: center; margin-bottom: 15px;
        box-shadow: 0 4px 6px rgba(0,0,0,0.3);
    }
    .metric-val { font-size: 32px; font-weight: 900; color: #3282b8; }
    .metric-lbl { font-size: 14px; color: #94a3b8; font-weight: bold; text-transform: uppercase; }

    /* è³‡è¨Šå¡ç‰‡ */
    .info-card {
        background-color: #111827; padding: 15px; border-radius: 8px; 
        border: 1px solid #374151; margin-bottom: 10px; font-size: 0.9em;
    }
</style>
""", unsafe_allow_html=True)

# --- 3. ç‹€æ…‹åˆå§‹åŒ– ---
if "analysis_report" not in st.session_state: st.session_state.analysis_report = ""
if "raw_context" not in st.session_state: st.session_state.raw_context = ""
if "sorted_models" not in st.session_state: st.session_state.sorted_models = []

# --- æ ¸å¿ƒï¼šæ¨¡å‹æ’åº ---
def sort_models_by_version(models):
    def score_model(name):
        score = 0
        if "gemini-3" in name: score += 5000
        elif "gemini-2.5" in name: score += 4000
        elif "gemini-1.5-pro" in name: score += 3000
        elif "gemini-1.5-flash" in name: score += 1000
        if "exp" in name: score -= 50
        return score
    return sorted(models, key=score_model, reverse=True)

# --- Word å°å‡º ---
def create_word_docx(markdown_text):
    doc = Document()
    doc.add_heading('TrendScope åˆ†æèˆ‡è…³æœ¬å ±å‘Š', 0).alignment = WD_ALIGN_PARAGRAPH.CENTER
    doc.add_paragraph(f"ç”Ÿæˆæ™‚é–“: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    
    for line in markdown_text.split('\n'):
        line = line.strip()
        if not line: continue
        if line.startswith('# '): doc.add_heading(line.replace('# ', ''), 1)
        elif line.startswith('## '): doc.add_heading(line.replace('## ', ''), 2)
        elif line.startswith('### '): doc.add_heading(line.replace('### ', ''), 3)
        elif line.startswith('- '): doc.add_paragraph(line.replace('- ', ''), style='List Bullet')
        elif line.startswith('|'): doc.add_paragraph(line, style='Intense Quote') # è¡¨æ ¼æˆ–å¼·èª¿
        else: doc.add_paragraph(line)
        
    buffer = BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer

# --- æª”æ¡ˆè™•ç† ---
def safe_remove(filepath):
    try:
        if os.path.exists(filepath):
            gc.collect()
            time.sleep(0.5)
            os.remove(filepath)
    except: pass

def load_image_safe(filepath):
    try:
        with Image.open(filepath) as img:
            img.load()
            return img.copy()
    except: return None

# --- å´é‚Šæ¬„ ---
with st.sidebar:
    st.title("ğŸ¬ æ§åˆ¶ä¸­å¿ƒ")
    api_key = st.text_input("Google API Key", type="password", value=st.session_state.get("api_key", ""))
    
    if st.button("ğŸ”„ æƒææ¨¡å‹æ¸…å–®"):
        if api_key:
            try:
                genai.configure(api_key=api_key)
                all_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
                st.session_state.sorted_models = sort_models_by_version(all_models)
                st.session_state.api_key = api_key
                st.success(f"æœ€ä½³æ¨¡å‹ï¼š{st.session_state.sorted_models[0]}")
            except Exception as e: st.error(f"éŒ¯èª¤: {e}")

    options = st.session_state.sorted_models if st.session_state.sorted_models else ["models/gemini-1.5-flash"]
    selected_model = st.selectbox("æ ¸å¿ƒå¼•æ“", options)
    
    st.info("ğŸ’¡ **è…³æœ¬ç”Ÿæˆå·²å•Ÿç”¨**\nAI å°‡è‡ªå‹•æ’°å¯«åˆ†é¡è…³æœ¬ï¼Œæ‚¨å¯ä»¥ç›´æ¥ä¸‹è¼‰ Word æª”ä½¿ç”¨ã€‚")

# --- å·¥å…·å‡½æ•¸ ---
def get_video_full_info(url):
    ydl_opts = {
        'quiet': True, 'noplaylist': True, 'extract_flat': True, 'skip_download': True,
        'http_headers': {'User-Agent': 'Mozilla/5.0'}
    }
    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(url, download=False)
            return {
                "title": info.get('title', 'Unknown'),
                "channel": info.get('uploader', 'Unknown'),
                "views": info.get('view_count', 0),
                "thumbnail_url": info.get('thumbnail', None)
            }
    except: return None

def download_image(url, idx):
    try:
        filename = f"thumb_{idx}_{int(time.time())}.jpg"
        res = requests.get(url, stream=True, timeout=10)
        if res.status_code == 200:
            with open(filename, 'wb') as f: f.write(res.content)
            return filename
    except: pass
    return None

def get_yt_transcript(video_id):
    try:
        t = YouTubeTranscriptApi.get_transcript(video_id, languages=['zh-TW', 'zh', 'en'])
        return TextFormatter().format_transcript(t)
    except: return None

def download_audio(url, idx):
    filename = f"audio_{idx}_{int(time.time())}.m4a"
    safe_remove(filename)
    ydl_opts = {
        'format': 'bestaudio[ext=m4a]/bestaudio', 'outtmpl': filename,
        'quiet': True, 'noplaylist': True, 'ignoreerrors': True, 'nocheckcertificate': True
    }
    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl: ydl.download([url])
        if os.path.exists(filename): return filename
        webm = filename.replace('.m4a', '.webm')
        if os.path.exists(webm): return webm
        return None
    except: return None

def safe_api_call(func, *args, **kwargs):
    max_retries = 3
    for attempt in range(max_retries):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            if "429" in str(e):
                time.sleep(10 * (attempt + 1))
            else: raise e
    raise Exception("API é‡è©¦å¤±æ•—")

# --- ä¸»ç¨‹å¼ ---
st.title("TrendScope Master | è…³æœ¬ç”Ÿæˆç‰ˆ")
st.markdown("### ğŸ’  å½±éŸ³è¼¿æƒ…èˆ‡è‡ªå‹•åŒ–è…³æœ¬ç³»çµ±")

tab1, tab2 = st.tabs(["ğŸ“º å½±éŸ³æ™ºæ…§åˆ†æ (YT/TikTok)", "ğŸ“¸ ç¤¾ç¾¤åœ–æ–‡åˆ†æ"])

urls_input = ""
imgs_input = []
txt_input = ""
mode = ""
data_inputs = []
temp_files = []
raw_context_builder = []

with tab1:
    urls_input = st.text_area("è¼¸å…¥ç¶²å€ (ä¸€è¡Œä¸€å€‹)", height=150, key="vid_in")
    analyze_vid_btn = st.button("ğŸš€ å•Ÿå‹•å®Œæ•´åˆ†æ + ç”Ÿæˆè…³æœ¬", key="btn_vid")
    if analyze_vid_btn: mode = "video"

with tab2:
    imgs_input = st.file_uploader("ä¸Šå‚³æˆªåœ–", accept_multiple_files=True, type=['png', 'jpg'])
    txt_input = st.text_area("è£œå……èªªæ˜", height=100)
    analyze_soc_btn = st.button("ğŸš€ å•Ÿå‹•å®Œæ•´åˆ†æ + ç”Ÿæˆæ–‡æ¡ˆ", key="btn_soc")
    if analyze_soc_btn: mode = "social"

# ================= é‚è¼¯æ ¸å¿ƒ =================

if (mode == "video" and urls_input) or (mode == "social" and (imgs_input or txt_input)):
    if not api_key:
        st.error("è«‹è¼¸å…¥ API Key")
    else:
        st.session_state.analysis_report = ""
        st.session_state.raw_context = ""
        
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(selected_model)

        with st.status("ğŸš€ æ­£åœ¨åŸ·è¡Œæ·±åº¦é‹ç®—...", expanded=True) as status:
            try:
                if mode == "video":
                    urls = [u.strip() for u in urls_input.split('\n') if u.strip()]
                    total = len(urls)
                    progress_bar = st.progress(0)
                    
                    for i, url in enumerate(urls):
                        status.update(label=f"ğŸ“¥ è§£æç´ æ {i+1}/{total}...", state="running")
                        
                        info = get_video_full_info(url)
                        if info:
                            thumb_path = None
                            if info.get('thumbnail_url'):
                                thumb_path = download_image(info['thumbnail_url'], i)
                                if thumb_path: temp_files.append(thumb_path)
                            
                            st.write(f"âœ… å·²è¼‰å…¥: {info['title']}")
                            
                            meta_str = f"ã€ç´ æ #{i+1} Metadataã€‘\næ¨™é¡Œ: {info['title']}\né »é“: {info['channel']}\nè§€çœ‹æ•¸: {info['views']}\n"
                            data_inputs.append(meta_str)
                            if thumb_path: data_inputs.append(thumb_path)
                            raw_context_builder.append(meta_str)

                            transcript = None
                            use_audio_first = "gemini-2.5" in selected_model or "gemini-3" in selected_model
                            
                            if not use_audio_first:
                                if "youtube" in url or "youtu.be" in url:
                                    vid_match = re.search(r'(?:v=|\/)([0-9A-Za-z_-]{11})', url)
                                    if vid_match: transcript = get_yt_transcript(vid_match.group(1))

                            if transcript:
                                trans_str = f"ç´ æ #{i+1} å­—å¹•:\n{transcript[:10000]}\n"
                                data_inputs.append(trans_str)
                                raw_context_builder.append(trans_str)
                            else:
                                status.update(label=f"ğŸ§ ç´ æ {i+1}: è½è¦ºåˆ†æä¸­...", state="running")
                                aud_path = download_audio(url, i)
                                if aud_path:
                                    data_inputs.append(aud_path)
                                    temp_files.append(aud_path)
                                    raw_context_builder.append(f"ç´ æ #{i+1}: [AI å·²è†è½éŸ³è¨Š]\n")
                        
                        progress_bar.progress((i + 1) / total)
                        if i < total - 1: time.sleep(2)

                else:
                    status.update(label="ğŸ“¸ è§£æåœ–ç‰‡...", state="running")
                    if txt_input: data_inputs.append(f"è£œå……: {txt_input}")
                    for i, img in enumerate(imgs_input):
                        data_inputs.append(f"\n=== æˆªåœ– #{i+1} ===\n")
                        data_inputs.append(Image.open(img))

                # --- Prompt è¨­è¨ˆ (åŠ å…¥ç¬¬4é»è…³æœ¬ç”Ÿæˆ) ---
                status.update(label=f"ğŸ§  {selected_model} æ­£åœ¨ç”Ÿæˆåˆ†æèˆ‡è…³æœ¬...", state="running")
                
                if mode == "video":
                    prompt = """
                    ä½ æ˜¯ä¸€ä½é¦–å¸­åª’é«”åˆ†æå¸«èˆ‡è…³æœ¬å°æ¼”ã€‚è«‹é€²è¡Œåˆ†æä¸¦ç”¢å‡ºè…³æœ¬ã€‚
                    
                    è«‹åš´æ ¼ä¾ç…§ä»¥ä¸‹çµæ§‹è¼¸å‡ºï¼š
                    
                    ========================================
                    PART 1: ğŸ”¬ å€‹åˆ¥æ·±åº¦è¨ºæ–· (Individual Analysis)
                    ========================================
                    (è«‹é‡å°æ¯ä¸€å€‹ç´ æï¼Œåˆ†åˆ¥ç°¡çŸ­åˆ†æï¼šæµé‡æ­¸å› (äººç´…/ç‰‡ç´…)ã€æ ¸å¿ƒäº®é»)

                    ========================================
                    PART 2: ğŸŒªï¸ ç¶œåˆæ­¸ç´çµ±æ•´ (Macro Synthesis)
                    ========================================
                    ## 1. å…±åŒçˆ†ç´…å…¬å¼
                    ## 2. æµé‡å„€è¡¨æ¿ (æŒ‡æ•¸/Hashtags)
                    ## 3. æœ€ä½³åŸ·è¡Œå»ºè­°

                    ========================================
                    PART 3: ğŸ”¥ å¯¦æˆ°ç”Ÿæˆï¼šçˆ†æ¬¾è…³æœ¬ (AI Script)
                    ========================================
                    è«‹æ¨¡ä»¿é€™æ¬¡åˆ†æä¸­**è¡¨ç¾æœ€å¥½ã€æœ€å€¼å¾—åƒè€ƒ**çš„é‚£æ”¯å½±ç‰‡çš„é¢¨æ ¼èˆ‡ç¯€å¥ï¼Œ
                    å¹«æˆ‘å¯«ä¸€å€‹ **30-60ç§’ çŸ­å½±éŸ³æ‹æ”è…³æœ¬**ã€‚ä¸»é¡Œè«‹è¨­å®šç‚ºèˆ‡åŸå½±ç‰‡é¡ä¼¼çš„é ˜åŸŸã€‚
                    
                    è«‹ä½¿ç”¨ä»¥ä¸‹æ ¼å¼ï¼š
                    **ã€è…³æœ¬æ¨™é¡Œã€‘**: (å¸ç›çš„æ¨™é¡Œ)
                    **ã€é æœŸæƒ…ç·’ã€‘**: (ä¾‹å¦‚ï¼šå¿«ç¯€å¥/æ‡¸ç–‘/æç¬‘)
                    
                    | æ™‚é–“ | ç•«é¢/é‹é¡ (Visual) | å°è©/æ—ç™½ (Audio) | å‚™è¨»/éŸ³æ•ˆ |
                    | --- | --- | --- | --- |
                    | 0-3s | (æè¿°é–‹é ­é‰¤å­) | (ç¬¬ä¸€å¥å°è©) | (éŸ³æ•ˆæç¤º) |
                    | ... | ... | ... | ... |
                    """
                else:
                    prompt = """
                    è«‹é€²è¡Œç¤¾ç¾¤è¼¿æƒ…åˆ†æã€‚
                    
                    PART 1: ğŸ“ å€‹åˆ¥æˆªåœ–è§£è®€
                    PART 2: ğŸŒªï¸ ç¶œåˆè¼¿æƒ…ç ”åˆ¤ (çˆ­è­°é»/é¢¨å‘/å»ºè­°)
                    
                    PART 3: ğŸ”¥ å¯¦æˆ°ç”Ÿæˆï¼šçˆ†æ¬¾æ–‡æ¡ˆ (AI Copywriting)
                    è«‹æ¨¡ä»¿é€™æ¬¡æœ€ç´…çš„è²¼æ–‡é¢¨æ ¼ï¼Œå¹«æˆ‘å¯«ä¸€ç¯‡é©åˆç™¼åœ¨ Threads/IG çš„æ–‡æ¡ˆã€‚
                    è«‹åŒ…å«ï¼š
                    - **å¸ç›é¦–åœ–å»ºè­°**
                    - **å…§æ–‡ (å«åˆ†æ®µèˆ‡ Emoji)**
                    - **å¼•å°ç•™è¨€çš„çµå°¾ (CTA)**
                    """

                response = safe_api_call(model.generate_content, data_inputs)
                st.session_state.analysis_report = response.text
                st.session_state.raw_context = "\n".join(raw_context_builder)
                
                status.update(label="âœ… å®Œæˆï¼", state="complete")

            except Exception as e:
                status.update(label="âŒ å¤±æ•—", state="error")
                st.error(f"åˆ†æå¤±æ•—: {e}")
            
            data_inputs = []
            gc.collect()
            for f in temp_files: safe_remove(f)

# ================= çµæœé¡¯ç¤º =================

if st.session_state.analysis_report:
    # å„€è¡¨æ¿
    try:
        res = st.session_state.analysis_report
        score_match = re.search(r"æŒ‡æ•¸.*(\d{2,3})", res)
        score = score_match.group(1) if score_match else "N/A"
        
        tag_match = re.search(r"(å¯†ç¢¼|æ¨™ç±¤).*[:ï¼š]\s*(.+)", res)
        tags = tag_match.group(1).split('\n')[0] if tag_match else "åˆ†æä¸­"
        
        c1, c2 = st.columns([1, 3])
        with c1: st.markdown(f'<div class="metric-card"><div class="metric-val">{score}</div><div class="metric-lbl">ğŸ”¥ ç¶œåˆç†±åº¦</div></div>', unsafe_allow_html=True)
        with c2: st.markdown(f'<div class="metric-card"><div class="metric-val" style="font-size:20px; color:#e2e8f0;">{tags}</div><div class="metric-lbl">ğŸ·ï¸ æ ¸å¿ƒé—œéµå­—</div></div>', unsafe_allow_html=True)
    except: pass

    # å®Œæ•´å ±å‘Š
    st.markdown('<div class="info-card">', unsafe_allow_html=True)
    st.markdown("### ğŸ“ å®Œæ•´åˆ†æèˆ‡è…³æœ¬")
    st.markdown(st.session_state.analysis_report)
    st.markdown('</div>', unsafe_allow_html=True)
    
    # å°å‡º
    c1, c2 = st.columns([1, 4])
    with c1:
        docx_file = create_word_docx(st.session_state.analysis_report)
        st.download_button("ğŸ“„ ä¸‹è¼‰ Word (å«è…³æœ¬)", docx_file, "Script_Report.docx", "application/vnd.openxmlformats-officedocument.wordprocessingml.document")
    with c2:
        st.download_button("ğŸ“¥ ä¸‹è¼‰ Markdown", st.session_state.analysis_report, "Report.md")

    # è¿½å•
    st.markdown("---")
    if prompt := st.chat_input("å°è…³æœ¬ä¸æ»¿æ„ï¼Ÿè«‹ AI ä¿®æ”¹ (ä¾‹å¦‚ï¼šæŠŠé–‹é ­æ”¹å¾—æ›´è³å‹•ä¸€é»)..."):
        with st.chat_message("user"): st.markdown(prompt)
        with st.chat_message("assistant"):
            with st.spinner("AI ä¿®æ”¹ä¸­..."):
                chat_model = genai.GenerativeModel(selected_model)
                full_prompt = f"ã€å ±å‘Šã€‘{st.session_state.analysis_report}\nã€åŸå§‹è¨˜æ†¶ã€‘{st.session_state.raw_context}\nã€ä¿®æ”¹è¦æ±‚ã€‘{prompt}"
                res = safe_api_call(chat_model.generate_content, full_prompt).text
                st.markdown(res)