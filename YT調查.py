import streamlit as st
from youtube_transcript_api import YouTubeTranscriptApi
from youtube_transcript_api.formatters import TextFormatter
import google.generativeai as genai
import yt_dlp
import os
import re
import time
import requests
from PIL import Image
import nest_asyncio
import gc
import random
from io import BytesIO
from docx import Document
from docx.shared import Pt, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH

nest_asyncio.apply()

# --- 1. é é¢è¨­å®š ---
st.set_page_config(
    page_title="TrendScope Future | 3.0 Ready",
    page_icon="ğŸª",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- 2. æœªä¾†æ„Ÿæ·±è‰² UI ---
st.markdown("""
<style>
    /* èƒŒæ™¯ï¼šæ·±ç©ºé»‘ */
    .stApp { background-color: #0B0F19 !important; color: #E2E8F0 !important; }
    h1, h2, h3, h4, .stMarkdown { color: #F8FAFC !important; }
    
    /* æŒ‰éˆ•ï¼šéœ“è™¹ç´« (Cyberpunk Style) */
    .stButton > button {
        background: linear-gradient(90deg, #7C3AED 0%, #DB2777 100%) !important;
        color: white !important;
        border: none !important;
        font-weight: 800; padding: 0.8rem; border-radius: 8px;
        text-transform: uppercase; letter-spacing: 1px;
        box-shadow: 0 0 15px rgba(124, 58, 237, 0.5);
    }
    .stButton > button:hover { box-shadow: 0 0 25px rgba(219, 39, 119, 0.7); transform: scale(1.02); }

    /* è¼¸å…¥æ¡† */
    .stTextArea textarea, .stTextInput input {
        background-color: #1E293B !important; color: #F1F5F9 !important; 
        border: 1px solid #334155 !important; border-radius: 6px;
    }
    .stTextArea textarea:focus { border-color: #DB2777 !important; }

    /* å¡ç‰‡èˆ‡ç‹€æ…‹ */
    .custom-card { background-color: #111827; padding: 25px; border: 1px solid #1F2937; border-radius: 12px; margin-bottom: 25px; }
    .model-tag { background-color: #374151; padding: 2px 8px; border-radius: 4px; font-size: 0.8em; color: #A5F3FC; }
    
    /* æ€è€ƒéç¨‹å€å¡Š */
    .thinking-box {
        background-color: #171717; border-left: 3px solid #7C3AED;
        padding: 10px; margin-bottom: 10px; font-family: monospace; font-size: 0.9em; color: #A3A3A3;
    }
</style>
""", unsafe_allow_html=True)

# --- 3. ç‹€æ…‹åˆå§‹åŒ– ---
if "analysis_report" not in st.session_state: st.session_state.analysis_report = ""
if "raw_context" not in st.session_state: st.session_state.raw_context = ""
if "sorted_models" not in st.session_state: st.session_state.sorted_models = []

# --- æ ¸å¿ƒï¼šæ¨¡å‹ç‰ˆæœ¬æ¼”ç®—æ³• ---
def sort_models_by_version(models):
    """
    è‡ªå‹•æ’åºæ¨¡å‹ï¼Œå„ªå…ˆé †åºï¼š3.0 > 2.5 > 2.0 > 1.5 > Pro > Flash
    """
    def score_model(name):
        score = 0
        if "gemini-3" in name: score += 5000
        elif "gemini-2.5" in name: score += 4000
        elif "gemini-2.0" in name: score += 3000
        elif "gemini-1.5" in name: score += 1000
        
        if "pro" in name: score += 500
        if "flash" in name: score += 300
        if "exp" in name or "preview" in name: score -= 50 # é è¦½ç‰ˆç¨å¾®æ‰£åˆ†(ä¸ç©©)ï¼Œä½†å¦‚æœæ˜¯3.0ä»æœƒæ’å‰é¢
        return score

    return sorted(models, key=score_model, reverse=True)

# --- Word å°å‡º ---
def create_word_docx(markdown_text):
    doc = Document()
    doc.add_heading('TrendScope æœªä¾†è¼¿æƒ…å ±å‘Š', 0).alignment = WD_ALIGN_PARAGRAPH.CENTER
    doc.add_paragraph(f"ç”Ÿæˆæ¨¡å‹: Gemini AI | æ™‚é–“: {time.strftime('%Y-%m-%d')}")
    
    for line in markdown_text.split('\n'):
        line = line.strip()
        if not line: continue
        if line.startswith('# '): doc.add_heading(line.replace('# ', ''), 1)
        elif line.startswith('## '): doc.add_heading(line.replace('## ', ''), 2)
        elif line.startswith('- '): doc.add_paragraph(line.replace('- ', ''), style='List Bullet')
        else: doc.add_paragraph(line)
        
    buffer = BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer

# --- æª”æ¡ˆè™•ç† ---
def safe_remove(filepath):
    try:
        if os.path.exists(filepath):
            gc.collect()
            time.sleep(0.5)
            os.remove(filepath)
    except: pass

def load_image_safe(filepath):
    try:
        with Image.open(filepath) as img:
            img.load()
            return img.copy()
    except: return None

# --- å´é‚Šæ¬„ ---
with st.sidebar:
    st.title("ğŸª æœªä¾†æ§åˆ¶å°")
    api_key = st.text_input("Google API Key", type="password", value=st.session_state.get("api_key", ""))
    
    if st.button("ğŸ”„ æƒææœ€æ–°æ¨¡å‹ (3.0/2.5)"):
        if api_key:
            try:
                genai.configure(api_key=api_key)
                all_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
                # åŸ·è¡Œæ™ºæ…§æ’åº
                st.session_state.sorted_models = sort_models_by_version(all_models)
                st.session_state.api_key = api_key
                st.success(f"å·²é–å®šæœ€æ–°æŠ€è¡“ï¼š{st.session_state.sorted_models[0]}")
            except Exception as e:
                st.error(f"é€£ç·šå¤±æ•—: {e}")

    options = st.session_state.sorted_models if st.session_state.sorted_models else ["models/gemini-1.5-flash"]
    selected_model = st.selectbox("æ ¸å¿ƒå¼•æ“", options)
    
    # é¡¯ç¤ºæ¨¡å‹æ¨™ç±¤
    if "gemini-3" in selected_model:
        st.markdown('<span class="model-tag">ğŸ”¥ Gemini 3.0 (Next Gen)</span>', unsafe_allow_html=True)
        st.caption("å…·å‚™ Agentic æ¨ç†èƒ½åŠ›ï¼Œèƒ½ç†è§£æ¥µå…¶è¤‡é›œçš„å› æœé—œä¿‚ã€‚")
    elif "gemini-2.5" in selected_model:
        st.markdown('<span class="model-tag">âš¡ Gemini 2.5 (Current Gen)</span>', unsafe_allow_html=True)
        st.caption("Native Audio å¢å¼·ï¼Œè½è¦ºåˆ†ææ›´æ•éŠ³ã€‚")
    
    use_thinking = st.toggle("ğŸ§  å•Ÿç”¨æ·±åº¦æ€è€ƒ (Chain-of-Thought)", value=True)

# --- å·¥å…·å‡½æ•¸ ---
def get_video_full_info(url):
    ydl_opts = {'quiet': True, 'noplaylist': True, 'extract_flat': True, 'skip_download': True}
    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(url, download=False)
            return {
                "title": info.get('title', 'Unknown'),
                "channel": info.get('uploader', 'Unknown'),
                "views": info.get('view_count', 0),
                "thumbnail_url": info.get('thumbnail', None)
            }
    except: return None

def download_image(url, idx):
    try:
        filename = f"thumb_{idx}_{int(time.time())}.jpg"
        response = requests.get(url, stream=True, timeout=10)
        if response.status_code == 200:
            with open(filename, 'wb') as f: f.write(response.content)
            return filename
    except: pass
    return None

def get_yt_transcript(video_id):
    try:
        t = YouTubeTranscriptApi.get_transcript(video_id, languages=['zh-TW', 'zh', 'en'])
        return TextFormatter().format_transcript(t)
    except: return None

def download_audio(url, idx):
    filename = f"audio_{idx}_{int(time.time())}.m4a"
    safe_remove(filename)
    ydl_opts = {'format': 'bestaudio[ext=m4a]/bestaudio', 'outtmpl': filename, 'quiet': True, 'noplaylist': True, 'ignoreerrors': True, 'nocheckcertificate': True}
    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl: ydl.download([url])
        if os.path.exists(filename): return filename
        return filename.replace('.m4a', '.webm') if os.path.exists(filename.replace('.m4a', '.webm')) else None
    except: return None

def safe_api_call(func, *args, **kwargs):
    max_retries = 3
    for attempt in range(max_retries):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            if "429" in str(e):
                st.toast(f"â³ è®“ {selected_model} ä¼‘æ¯ä¸€ä¸‹... ({attempt+1})")
                time.sleep(10 * (attempt + 1))
            else: raise e
    raise Exception("API é‡è©¦å¤±æ•—")

# --- ä¸»ç¨‹å¼ ---
st.title("TrendScope Future | 3.0 Ready")
st.markdown('<div class="custom-card">', unsafe_allow_html=True)
tab1, tab2 = st.tabs(["ğŸ“º å½±éŸ³æ·±åº¦åˆ†æ", "ğŸ“¸ ç¤¾ç¾¤è¼¿æƒ…åˆ†æ"])

urls_input = ""
imgs_input = []
txt_input = ""
mode = ""

with tab1:
    urls_input = st.text_area("YouTube / TikTok ç¶²å€", height=150, key="vid_in")
    analyze_vid_btn = st.button("ğŸš€ å•Ÿå‹• 3.0 å¼•æ“åˆ†æ", key="btn_vid")
    if analyze_vid_btn: mode = "video"

with tab2:
    imgs_input = st.file_uploader("ä¸Šå‚³æˆªåœ–", accept_multiple_files=True, type=['png', 'jpg'])
    txt_input = st.text_area("è£œå……èªªæ˜", height=100)
    analyze_soc_btn = st.button("ğŸš€ å•Ÿå‹• 3.0 å¼•æ“åˆ†æ", key="btn_soc")
    if analyze_soc_btn: mode = "social"

st.markdown('</div>', unsafe_allow_html=True)

# ================= é‚è¼¯æ ¸å¿ƒ =================

if (mode == "video" and urls_input) or (mode == "social" and (imgs_input or txt_input)):
    if not api_key:
        st.error("è«‹è¼¸å…¥ API Key")
    else:
        st.session_state.analysis_report = ""
        st.session_state.raw_context = ""
        
        data_inputs = []
        raw_context_builder = []
        temp_files = []
        
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(selected_model)

        with st.status("ğŸš€ æ­£åœ¨åˆå§‹åŒ–å¤šæ¨¡æ…‹åˆ†æ...", expanded=True) as status:
            try:
                if mode == "video":
                    urls = [u.strip() for u in urls_input.split('\n') if u.strip()]
                    total = len(urls)
                    progress_bar = st.progress(0)
                    
                    for i, url in enumerate(urls):
                        status.update(label=f"ğŸ“¥ è§£æç´ æ {i+1}/{total}...", state="running")
                        info = get_video_full_info(url)
                        
                        if info:
                            thumb_path = None
                            if info.get('thumbnail_url'):
                                thumb_path = download_image(info['thumbnail_url'], i)
                                if thumb_path: temp_files.append(thumb_path)
                            
                            meta_str = f"ã€ç´ æ #{i+1}ã€‘\næ¨™é¡Œ: {info['title']}\né »é“: {info['channel']}\nè§€çœ‹æ•¸: {info['views']}\n"
                            data_inputs.append(meta_str)
                            if thumb_path: data_inputs.append(thumb_path)
                            raw_context_builder.append(meta_str)

                            # 2.5/3.0 å¼·é …ï¼šNative Audio
                            # æˆ‘å€‘ä¸å†å„ªå…ˆæŠ“å­—å¹•ï¼Œå¦‚æœæ¨¡å‹æ˜¯æ–°çš„ï¼Œæˆ‘å€‘å„ªå…ˆçµ¦å®ƒè½è²éŸ³ï¼
                            is_native_audio_model = "gemini-2.5" in selected_model or "gemini-3" in selected_model
                            
                            transcript = None
                            # åªæœ‰åœ¨èˆŠæ¨¡å‹æˆ–éYTæ™‚æ‰ä¾è³´å­—å¹•
                            if not is_native_audio_model and ("youtube" in url or "youtu.be" in url):
                                vid_match = re.search(r'(?:v=|\/)([0-9A-Za-z_-]{11})', url)
                                if vid_match: transcript = get_yt_transcript(vid_match.group(1))
                            
                            if transcript:
                                data_inputs.append(f"ç´ æ #{i+1} å­—å¹•:\n{transcript[:15000]}\n")
                                raw_context_builder.append(f"ç´ æ #{i+1} å­—å¹•å·²æä¾›\n")
                            else:
                                status.update(label=f"ğŸ§ ä¸‹è¼‰éŸ³è¨Š (ä½¿ç”¨ Native Audio åˆ†æ)...", state="running")
                                aud_path = download_audio(url, i)
                                if aud_path:
                                    data_inputs.append(aud_path)
                                    temp_files.append(aud_path)
                                    raw_context_builder.append(f"ç´ æ #{i+1}: [AI å·²ç›´æ¥è†è½éŸ³è¨Šå…§å®¹]\n")
                        
                        progress_bar.progress((i + 1) / total)
                        if i < total - 1: time.sleep(2) # é¿è®“ 429

                else:
                    status.update(label="ğŸ“¸ è§£æè¦–è¦ºç´°ç¯€...", state="running")
                    if txt_input: data_inputs.append(f"è£œå……: {txt_input}")
                    for i, img in enumerate(imgs_input):
                        data_inputs.append(f"\n=== æˆªåœ– #{i+1} ===\n")
                        data_inputs.append(Image.open(img))

                # --- Prompt è¨­è¨ˆ ---
                thinking_instruction = ""
                if use_thinking:
                    thinking_instruction = """
                    ã€æ€è€ƒç¨‹åº (Thought Process)ã€‘
                    åœ¨è¼¸å‡ºæ­£å¼å ±å‘Šå‰ï¼Œè«‹å…ˆé€²è¡Œä¸€æ®µã€Œæ·±åº¦æ¨ç†ã€ï¼š
                    1. æ‡·ç–‘ï¼šé€™æ˜¯ä¸æ˜¯å€–å­˜è€…åå·®ï¼Ÿ
                    2. æ¯”å°ï¼šé€™å€‹æ¨¡å¼åœ¨å…¶ä»–åœ°æ–¹è¦‹éå—ï¼Ÿ
                    3. é©—è­‰ï¼šå¦‚æœå»æ‰åäººå…‰ç’°ï¼Œé€™å€‹è…³æœ¬é‚„æˆç«‹å—ï¼Ÿ
                    (è«‹å°‡é€™æ®µæ€è€ƒéç¨‹æ¨™è¨»åœ¨å ±å‘Šæœ€å‰æ–¹)
                    """

                if mode == "video":
                    prompt = f"""
                    ä½ ç¾åœ¨æ˜¯ {selected_model}ï¼Œæ“æœ‰æœ€å¼·çš„å¤šæ¨¡æ…‹ç†è§£èƒ½åŠ›ã€‚
                    è«‹åˆ†æé€™äº›ç´ æã€‚{thinking_instruction}
                    
                    è«‹åš´æ ¼ä¾ç…§å…©éšæ®µè¼¸å‡ºï¼š
                    
                    # ç¬¬ä¸€éšæ®µï¼šğŸ”¬ å€‹åˆ¥æ·±åº¦è¨ºæ–·
                    (é‡å°æ¯å€‹ç´ æï¼Œåˆ†æå…¶ï¼š1. å¿ƒç†å­¸é‰¤å­ 2. è½è¦ºèªæ°£æ½›å°è© 3. çˆ†ç´…æ­¸å› )
                    
                    # ç¬¬äºŒéšæ®µï¼šğŸŒªï¸ å®è§€ç­–ç•¥èˆ‡å¯¦æˆ°
                    ## 1. æµé‡å¯†ç¢¼ (The Algorithm)
                    ## 2. å¯¦æˆ°è…³æœ¬ç”Ÿæˆ (è«‹å¹«æˆ‘å¯«ä¸€å€‹ 30 ç§’é–‹é ­è…³æœ¬ï¼Œæ¨¡ä»¿è¡¨ç¾æœ€å¥½çš„é‚£æ”¯)
                    ## 3. é¿å‘æŒ‡å—
                    """
                else:
                    prompt = f"""
                    ä½ ç¾åœ¨æ˜¯ {selected_model}ã€‚è«‹åˆ†æé€™äº›ç¤¾ç¾¤è¼¿æƒ…ã€‚{thinking_instruction}
                    
                    # ç¬¬ä¸€éšæ®µï¼šğŸ“ ç´°ç¯€è§£è®€
                    # ç¬¬äºŒéšæ®µï¼šğŸŒªï¸ ç¶œåˆç­–ç•¥
                    ## 1. æ ¸å¿ƒçˆ­è­°é»
                    ## 2. å±æ©Ÿè™•ç†/è·Ÿé¢¨å»ºè­°
                    ## 3. æ¨¡æ“¬æ–‡æ¡ˆç”Ÿæˆ (å¯«ä¸€ç¯‡ Threads å»¢æ–‡)
                    """

                status.update(label=f"ğŸ§  {selected_model} æ­£åœ¨é€²è¡Œæ·±åº¦æ¨ç†...", state="running")
                response = safe_api_call(model.generate_content, data_inputs)
                st.session_state.analysis_report = response.text
                st.session_state.raw_context = "\n".join(raw_context_builder)
                
                status.update(label="âœ… åˆ†æå®Œæˆï¼", state="complete")

            except Exception as e:
                status.update(label="âŒ å¤±æ•—", state="error")
                st.error(f"åˆ†æå¤±æ•—: {e}")
            
            data_inputs = []
            gc.collect()
            for f in temp_files: safe_remove(f)

# ================= çµæœèˆ‡å°å‡º =================

if st.session_state.analysis_report:
    st.markdown('<div class="custom-card">', unsafe_allow_html=True)
    st.markdown("### ğŸ” æ·±åº¦åˆ†æå ±å‘Š")
    
    # ç°¡å–®å‘ˆç¾æ€è€ƒéç¨‹ (å¦‚æœæœ‰çš„è©±)
    if "æ€è€ƒç¨‹åº" in st.session_state.analysis_report or "æ·±åº¦æ¨ç†" in st.session_state.analysis_report:
        st.markdown('<div class="thinking-box">ğŸ¤– AI æ€è€ƒè¿´è·¯å·²å•Ÿå‹•... (è©³è¦‹å ±å‘Šå…§å®¹)</div>', unsafe_allow_html=True)
        
    st.markdown(st.session_state.analysis_report)
    st.markdown('</div>', unsafe_allow_html=True)
    
    col1, col2 = st.columns([1, 4])
    with col1:
        docx_file = create_word_docx(st.session_state.analysis_report)
        st.download_button("ğŸ“„ ä¸‹è¼‰ Word (.docx)", docx_file, "Future_Report.docx", "application/vnd.openxmlformats-officedocument.wordprocessingml.document")
    with col2:
        st.download_button("ğŸ“¥ ä¸‹è¼‰ Markdown (.md)", st.session_state.analysis_report, "Future_Report.md")

    st.markdown("---")
    if prompt := st.chat_input("å‘ 3.0 å¼•æ“æå•..."):
        with st.chat_message("user"): st.markdown(prompt)
        with st.chat_message("assistant"):
            with st.spinner("AI æ€è€ƒä¸­..."):
                chat_model = genai.GenerativeModel(selected_model)
                full_prompt = f"ã€å ±å‘Šã€‘{st.session_state.analysis_report}\nã€åŸå§‹è³‡æ–™ã€‘{st.session_state.raw_context}\nã€å•é¡Œã€‘{prompt}"
                res = safe_api_call(chat_model.generate_content, full_prompt).text
                st.markdown(res)